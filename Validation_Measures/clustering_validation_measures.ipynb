{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering_validation_measures.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_A176yKf6DMd",
        "colab_type": "text"
      },
      "source": [
        "# Clustering Validation Measures\n",
        "\n",
        "Normalized Mutual Information (NMI) and Jaccard similarity will be implemented in this exercise.\n",
        "\n",
        "NMI is a normalized measure of mutual dependance between two sets. It quantifies the \"amount of information\" obtained about one set through observing the other set. The concept of mutual information is intricately linked to that of entropy of a set, a fundamental notion in information theory that quantifies the expected \"amount of information\" held in a random variable.\n",
        "\n",
        "The Jaccard Similarity compares members of two sets to see which members are shared and which are distinct. It's a measure of similarity for the two sets of data, with a range from 0% to 100%. The higher the percentage, the more similar the two populations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPuy5vcP6i5l",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "\n",
        "The ground-truth clustering (partition) results are stored in file \"partitions.txt\" and the five clustering result test cases are stored in file \"clustering_1.txt\", ..., \"clustering_5.txt\". Each line in a file consists of two integers, separated by a space. The first integer represents the id of a data item, and the second integer represents the id of the cluster which this item belongs to. Evaluate the clustering test cases with regard to the ground-truth using NMI and Jaccard Similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrFHjCui1Euu",
        "colab_type": "text"
      },
      "source": [
        "Read the clustering and partitions text files as dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahpuMSid3ckY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "clustering1_df = pd.read_csv('clustering_1.txt', header=None, sep=\" \")\n",
        "clustering2_df = pd.read_csv('clustering_2.txt', header=None, sep=\" \")\n",
        "clustering3_df = pd.read_csv('clustering_3.txt', header=None, sep=\" \")\n",
        "clustering4_df = pd.read_csv('clustering_4.txt', header=None, sep=\" \")\n",
        "clustering5_df = pd.read_csv('clustering_5.txt', header=None, sep=\" \")\n",
        "\n",
        "partitions_df = pd.read_csv('partitions.txt', header=None, sep=\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqr55KIx1Pir",
        "colab_type": "text"
      },
      "source": [
        "Create lists of labels from the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCTduhW5J0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering1_list = clustering1_df[1].tolist()\n",
        "clustering2_list = clustering2_df[1].tolist()\n",
        "clustering3_list = clustering3_df[1].tolist()\n",
        "clustering4_list = clustering4_df[1].tolist()\n",
        "clustering5_list = clustering5_df[1].tolist()\n",
        "\n",
        "partitions_list = partitions_df[1].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMckrEjw11ZE",
        "colab_type": "text"
      },
      "source": [
        "Create a function to find Normalized Mutual Information and Jaccard Similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we3Tksp95RhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "from scipy.special import comb\n",
        "\n",
        "def clustering(pred, true):\n",
        "  total_pred = len(pred)      # find the total count of all clusters in predicted labels\n",
        "  counts_pred = Counter(pred) # find the count of each cluster in predicted labels\n",
        "  counts_true = Counter(true) # find the count of each cluster in true labels\n",
        "\n",
        "  comb_labels = [(c,t) for c,t in zip(pred, true)] # combine the pred and true labels at index\n",
        "  counts_comb = Counter(comb_labels)               # find the count of each cluster in combined labels\n",
        "  \n",
        "  ### Normalized Mutual Information - START ###\n",
        "\n",
        "  mi = 0\n",
        "  for k,v in counts_comb.items():\n",
        "    c,t = k                        # extract just the clusters in the combined labels without their counts\n",
        "    pij = v/total_pred             # divide the count of each cluster in combined labels with the total count of all clusters in predicted labels\n",
        "    pc = counts_pred[c]/total_pred # divide the count of each cluster in predicted labels with the total count of all clusters in predicted labels\n",
        "    pt = counts_true[t]/total_pred # divide the count of each cluster in true labels with the total count of all clusters in predicted labels\n",
        "    mi += pij*np.log(pij/(pc*pt))  # find mutual information\n",
        "  \n",
        "  H_pred = 0\n",
        "  for i in counts_pred.values():\n",
        "    p_pred = i/total_pred           # divide the count of each cluster in predicted labels with the total count of all clusters in predicted labels\n",
        "    H_pred -= p_pred*np.log(p_pred) # find entropy of predicted labels\n",
        "  \n",
        "  H_true = 0\n",
        "  for i in counts_true.values():\n",
        "    p_true = i/total_pred           # divide the count of each cluster in true labels with the total count of all clusters in true labels\n",
        "    H_true -= p_true*np.log(p_true) # find entropy of true labels\n",
        "\n",
        "  nmi = mi/np.sqrt(H_pred*H_true)   # find normalized mutual information\n",
        "\n",
        "  ### Normalized Mutual Information - STOP ###\n",
        "\n",
        "  ### Jaccard Similarity - START ###\n",
        "\n",
        "  TP = 0\n",
        "  for k,v in counts_comb.items():\n",
        "    TP += v**2\n",
        "  TP  = 0.5*(TP - total_pred) # find true positive\n",
        "  \n",
        "  FN = 0\n",
        "  for k,v in counts_pred.items():\n",
        "    FN += comb(v,2)\n",
        "  FN -= TP                    # find false negative\n",
        "  \n",
        "  FP = 0\n",
        "  for k,v in counts_true.items():\n",
        "    FP += comb(v,2)\n",
        "  FP -= TP                    # find false positive\n",
        "\n",
        "  jaccard = TP/(TP+FN+FP)     # find jaccard similarity\n",
        "\n",
        "  ### Jaccard Similarity - STOP ###\n",
        "\n",
        "  return str(nmi)+\" \"+str(jaccard)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZAMSXQA7LvX",
        "colab_type": "text"
      },
      "source": [
        "## Ouput\n",
        "\n",
        "A file consisting of 5 lines to be created where each line contains two float numbers\n",
        "separated by a space. The first number of the i-th line represents the NMI measure calculated\n",
        "for the i-th test case (i.e. \"clustering_i.txt\") with regard to the ground-truth given in \"partitions.txt\", and the second number of the i-th line represents the Jaccard measure you calculated for the i-th test case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WRbOEix2Oy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering_lists = [clustering1_list, clustering2_list, clustering3_list, clustering4_list, clustering5_list]\n",
        "\n",
        "with open('scores.txt', 'a') as f:\n",
        "  for i in clustering_lists:\n",
        "    f.write(clustering(i, partitions_list)+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}